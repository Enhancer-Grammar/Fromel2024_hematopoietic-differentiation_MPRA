{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch.nn as nn\n",
    "\n",
    "import seqpro as sp\n",
    "import seqmodels as sm\n",
    "import seqdata as sd\n",
    "import seqexplainer as se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report cuda availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "os.chdir(\"/cellar/users/aklie/projects/ML4GLand/SeqModels/use_cases/case_3/DeepSTARR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SeqData\n",
    "training_sdata = sd.open_zarr(\"/cellar/users/aklie/data/datasets/deAlmeida_DrosophilaS2_UMI-STARR-seq/training/2023_12_19/seqdatasets/deAlmeida22_training.zarr\").load()\n",
    "test_sdata = sd.open_zarr(\"/cellar/users/aklie/data/datasets/deAlmeida_DrosophilaS2_UMI-STARR-seq/training/2023_12_19/seqdatasets/deAlmeida22_test.zarr\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single target variable to predict\n",
    "training_sdata[\"target\"] = xr.concat([training_sdata[\"Dev_log2_enrichment\"], training_sdata[\"Hk_log2_enrichment\"]], dim=\"_targets\").transpose(\"_sequence\", \"_targets\")\n",
    "test_sdata[\"target\"] = xr.concat([test_sdata[\"Dev_log2_enrichment\"], test_sdata[\"Hk_log2_enrichment\"]], dim=\"_targets\").transpose(\"_sequence\", \"_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some test seqs\n",
    "test_seqs = torch.tensor(training_sdata[\"ohe_seq\"][:10].values, dtype=torch.float32)\n",
    "test_dict = {\"seq\": test_seqs}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the architecture with SeqModels\n",
    "arch = sm.DeepSTARR(input_len=249, output_dim=2)\n",
    "arch, arch(test_seqs).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqmodels import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create module for training\n",
    "module = Module(\n",
    "    arch=arch,\n",
    "    input_vars=[\"ohe_seq\"],\n",
    "    output_vars=[\"output\"],\n",
    "    target_vars=[\"target\"],\n",
    "    loss_fxn=\"mse\",\n",
    "    train_metrics_fxn=[\"r2\", \"pearson\", \"spearman\"],\n",
    "    val_metrics_fxn=[\"r2\", \"pearson\", \"spearman\"],\n",
    "    scheduler=\"reduce_lr_on_plateau\",\n",
    ")\n",
    "module, module(test_dict).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into training and validation\n",
    "train_sdata = training_sdata.sel(_sequence=(training_sdata[\"train_val\"]==True).compute())\n",
    "valid_sdata = training_sdata.sel(_sequence=(training_sdata[\"train_val\"]==False).compute())\n",
    "train_sdata.dims[\"_sequence\"], valid_sdata.dims[\"_sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataloader\n",
    "train_dl = sd.get_torch_dataloader(\n",
    "    train_sdata.load(),\n",
    "    sample_dims=\"_sequence\",\n",
    "    variables=[\"ohe_seq\", \"target\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "batch = next(iter(train_dl))\n",
    "batch[\"ohe_seq\"].shape, batch[\"target\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataloader\n",
    "valid_dl = sd.get_torch_dataloader(\n",
    "    valid_sdata.load(),\n",
    "    sample_dims=\"_sequence\",\n",
    "    variables=[\"ohe_seq\", \"target\"],\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "batch = next(iter(valid_dl))\n",
    "batch[\"ohe_seq\"].shape, batch[\"target\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "logger = CSVLogger(save_dir=\"log\", name=\"\", version=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ModelCheckpoint, EarlyStopping and LearningRateMonitor callbacks\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "callbacks = [\n",
    "ModelCheckpoint(\n",
    "    dirpath=os.path.join(\n",
    "        logger.save_dir, \n",
    "        logger.name, \n",
    "        logger.version, \n",
    "        \"checkpoints\"\n",
    "    ),\n",
    "    save_top_k=5,\n",
    "    monitor=\"val_loss_epoch\",\n",
    "    mode=\"min\",\n",
    "),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss_epoch\",\n",
    "        patience=10,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    LearningRateMonitor(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=100,\n",
    "    check_val_every_n_epoch=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the weigths\n",
    "trainer.fit(module, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model weights\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "copy_path = os.path.join(\"best_model.ckpt\")\n",
    "os.system(f\"cp {best_model_path} {copy_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and metric curves\n",
    "training_summary(logger.save_dir, logger=\"csv\", metrics=[\"r2\", \"pearson\", \"spearman\"], save=\"training_summary.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "module = Module.load_from_checkpoint(\"best_model.ckpt\", arch=arch).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and targets as arrays\n",
    "preds_dict = module.predict({\"seq\": test_sdata[\"ohe_seq\"].values.astype(\"float32\")})\n",
    "preds = preds_dict[\"output\"].cpu().numpy().squeeze()\n",
    "targets = test_sdata[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "df = pd.DataFrame({\n",
    "    \"Dev_log2_enrichment\": targets[:, 0],\n",
    "    \"Hk_log2_enrichment\": targets[:, 1],\n",
    "    \"pred_Dev_log2_enrichment\": preds[:, 0],\n",
    "    \"pred_Hk_log2_enrichment\": preds[:, 1],\n",
    "})\n",
    "df.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a nice blue color\n",
    "scatter(\n",
    "    x=targets[:, 0],\n",
    "    y=preds[:, 0],\n",
    "    c=\"#4682B4\",\n",
    "    alpha=0.8,\n",
    "    xlabel=\"Experimental binding scores\",\n",
    "    ylabel=\"Predicted binding scores\",\n",
    "    density=True,\n",
    "    rasterized=True,\n",
    "    s=5,\n",
    "    save=\"Dev_log2_enrichment_scatter.png\",\n",
    ")\n",
    "scatter(\n",
    "    x=targets[:, 1],\n",
    "    y=preds[:, 1],\n",
    "    c=\"#4682B4\",\n",
    "    alpha=0.8,\n",
    "    xlabel=\"Experimental binding scores\",\n",
    "    ylabel=\"Predicted binding scores\",\n",
    "    density=True,\n",
    "    rasterized=True,\n",
    "    s=5,\n",
    "    save=\"Hk_log2_enrichment_scatter.png\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpnetlite.attributions import hypothetical_attributions\n",
    "from seqexplainer.attributions import plot_attribution_logo\n",
    "from seqexplainer.attributions._references import k_shuffle_ref_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the number of sequences and number of references per sequence\n",
    "n_seqs, n_refs = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the sequences and references\n",
    "seqs = test_sdata[\"ohe_seq\"].values[:100]\n",
    "refs = torch.tensor(k_shuffle_ref_inputs(seqs, k=2, n_per_input=n_refs), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape them to be compatible with Captum\n",
    "inputs = torch.tensor(seqs, dtype=torch.float32).repeat_interleave(n_refs, dim=0)\n",
    "baselines = refs.reshape(-1, *refs.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff64809a2915496eb97ff88a32d6d3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing attributions on batches of size 128:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get hypothetical attributions\n",
    "attrs = se.attribute(\n",
    "    model=module.arch,\n",
    "    inputs=inputs[:n_seqs*n_refs],\n",
    "    method=\"DeepLift\",\n",
    "    references=baselines[:n_seqs*n_refs],\n",
    "    target=0,\n",
    "    batch_size=128,\n",
    "    device=\"cuda\",\n",
    "    custom_attribution_func=hypothetical_attributions,\n",
    "    hypothetical=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average hypothetical attributions per sequence\n",
    "attrs = torch.tensor(attrs, dtype=torch.float32)\n",
    "attr_shape = (n_seqs, n_refs) + attrs.shape[1:]\n",
    "attrs = torch.mean(attrs.view(attr_shape), dim=1, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply by inputs\n",
    "attrs = attrs.cpu() * seqs[:n_seqs]\n",
    "attrs = attrs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ohe seqs as npz\n",
    "np.savez_compressed(\"attributions/test_ohe.npz\", seqs)\n",
    "np.savez_compressed(\"attributions/test_shap.npz\", attrs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
